{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_model(output_dim, num_cards):\n",
    "    \n",
    "    input_dim_rank = 13\n",
    "    input_dim_suit = 4\n",
    "    input_dim_card = 52\n",
    "\n",
    "    cards_input = tf.keras.Input((num_cards,))\n",
    "\n",
    "    #### EMBEDDING MODEL (used for each group of cards)\n",
    "    \n",
    "    rank_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim_rank, output_dim, embeddings_initializer='uniform',\n",
    "        embeddings_regularizer=None, activity_regularizer=None,\n",
    "        embeddings_constraint=None, mask_zero=False, input_length=None,\n",
    "    )\n",
    "\n",
    "    suit_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim_suit, output_dim, embeddings_initializer='uniform',\n",
    "        embeddings_regularizer=None, activity_regularizer=None,\n",
    "        embeddings_constraint=None, mask_zero=False, input_length=None,\n",
    "    )\n",
    "\n",
    "    card_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim_card, output_dim, embeddings_initializer='uniform',\n",
    "        embeddings_regularizer=None, activity_regularizer=None,\n",
    "        embeddings_constraint=None, mask_zero=False, input_length=None,\n",
    "    )\n",
    "\n",
    "    # cards is a list of card indices (2 for preflop, 3 for flop, 1 for turn, 1 for river)\n",
    "\n",
    "    #x = tf.keras.layers.Flatten()(cards_input)\n",
    "    x = cards_input\n",
    "    valid = tf.cast(x >= tf.constant(0.), tf.float32)\n",
    "\n",
    "    x = tf.clip_by_value(x, clip_value_min = 0, clip_value_max = 1e6)\n",
    "    \n",
    "    embs = card_embedding(x) + rank_embedding(x // 4) + suit_embedding(x%4)\n",
    "    \n",
    "    embs = embs * tf.expand_dims(valid, axis=-1)\n",
    "        \n",
    "    embs = tf.reduce_sum(embs , axis=1) # sum over num_cards card embeddings\n",
    "    \n",
    "    model = tf.keras.Model(cards_input, embs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "#card1 = tf.keras.layers.Dense(output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_embedding_model(256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_input = tf.constant([[1,10,3], \n",
    "                           #[[1],[10],[3]], \n",
    "                           #[[1],[10],[3]], \n",
    "                           #[[1],[10],[3]]\n",
    "                          ],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 256), dtype=float32, numpy=\n",
       "array([[-1.18423045e-01,  1.26143247e-02,  2.32719574e-02,\n",
       "         1.09996662e-01,  9.07058716e-02,  4.27301191e-02,\n",
       "        -7.79047459e-02, -1.15122154e-01,  1.08759120e-01,\n",
       "        -1.34283260e-01, -4.10801768e-02,  1.74363822e-01,\n",
       "        -1.92203037e-02,  1.03308372e-01,  6.82244003e-02,\n",
       "        -1.47374958e-01, -6.16319329e-02,  8.32098201e-02,\n",
       "         2.48851016e-01,  3.64313200e-02,  2.13759989e-02,\n",
       "         6.92469031e-02,  8.32180828e-02,  1.48655456e-02,\n",
       "         4.25132886e-02, -3.21364887e-02, -2.21473277e-02,\n",
       "         2.27494970e-01,  1.30238757e-02, -8.74953642e-02,\n",
       "         2.63550609e-01,  5.74711040e-02,  1.09141007e-01,\n",
       "        -2.11192071e-02,  1.62717760e-01,  1.10640056e-01,\n",
       "         6.56881258e-02,  3.80837545e-02,  3.08267772e-05,\n",
       "         1.67228103e-01, -5.75805753e-02, -1.69220358e-01,\n",
       "         1.84688754e-02, -5.91592789e-02,  1.29773840e-02,\n",
       "         4.65814248e-02,  7.06939921e-02,  8.36270750e-02,\n",
       "         2.04063147e-01,  1.84143811e-01, -1.34805515e-02,\n",
       "         1.59662776e-02, -8.91817510e-02,  8.75384361e-02,\n",
       "        -2.06183344e-02,  9.87065956e-02,  9.20267776e-02,\n",
       "        -8.83497000e-02,  1.30884990e-01, -1.24181040e-01,\n",
       "         1.21054374e-01, -9.88908485e-03, -1.45316720e-01,\n",
       "         3.68964598e-02, -1.92576088e-02,  2.57749520e-02,\n",
       "        -4.04243357e-02, -1.05152555e-01,  2.60885060e-03,\n",
       "         2.03461498e-01,  1.37788743e-01, -1.33144319e-01,\n",
       "        -9.35948864e-02,  6.02844171e-02, -8.79132599e-02,\n",
       "        -1.20685279e-01,  8.14950764e-02,  1.28858179e-01,\n",
       "         7.81917423e-02, -5.52359484e-02,  6.13058060e-02,\n",
       "        -1.57857612e-02, -9.58611816e-03,  1.38888076e-01,\n",
       "         3.83181237e-02, -1.00790620e-01,  8.64000469e-02,\n",
       "         1.12357691e-01,  2.76743993e-02, -3.52095179e-02,\n",
       "         1.07037120e-01,  2.52998807e-03,  9.83083248e-02,\n",
       "        -1.02609217e-01, -7.41451830e-02,  7.29999319e-03,\n",
       "         1.22183487e-02, -9.53897238e-02,  4.49568033e-05,\n",
       "         3.71025465e-02,  1.05205357e-01, -1.07215092e-01,\n",
       "        -3.00225988e-02, -3.68341655e-02, -2.53849886e-02,\n",
       "         3.41283269e-02, -8.07752609e-02,  5.84846698e-02,\n",
       "         5.91969676e-02,  6.24584667e-02, -1.46520138e-03,\n",
       "        -6.46047369e-02, -7.71796331e-03, -4.87145707e-02,\n",
       "         5.13050705e-02, -1.79659985e-02, -1.75778493e-01,\n",
       "         5.35529107e-04,  9.64856707e-03,  2.25919113e-03,\n",
       "         1.09930113e-02, -9.93156135e-02, -4.19744179e-02,\n",
       "         2.65991539e-02,  2.29366831e-02,  9.47591737e-02,\n",
       "        -6.46878406e-03,  7.28028715e-02,  7.44168088e-03,\n",
       "        -3.29991691e-02, -5.59883565e-03, -9.03501809e-02,\n",
       "        -3.18057150e-01,  1.56564862e-02,  4.01232056e-02,\n",
       "        -1.60950497e-02, -4.36099023e-02,  1.58651516e-01,\n",
       "         1.53703094e-01, -1.73338354e-01,  5.57381585e-02,\n",
       "        -4.25595827e-02, -9.79733020e-02,  3.91274840e-02,\n",
       "         1.08713776e-01,  9.30668563e-02,  1.22597136e-01,\n",
       "        -1.47284776e-01,  2.54005730e-01,  5.53486496e-02,\n",
       "        -7.53349811e-02,  1.88951537e-01, -4.72433642e-02,\n",
       "        -1.08495958e-01,  8.47299844e-02, -2.25793093e-01,\n",
       "        -4.71200310e-02,  1.06861919e-01, -8.25108290e-02,\n",
       "         9.41587090e-02,  7.71744624e-02, -7.37790018e-02,\n",
       "         1.02502495e-01, -5.75546809e-02, -7.80371577e-02,\n",
       "        -2.97091529e-02,  4.83737886e-02,  1.63185894e-01,\n",
       "         2.81693600e-03,  4.21006978e-03,  9.04259086e-03,\n",
       "        -1.63919121e-01,  5.27051985e-02, -5.20975851e-02,\n",
       "        -1.32206455e-02, -1.00670025e-01, -1.25788674e-01,\n",
       "         1.17353231e-01, -4.80620824e-02,  4.31765243e-03,\n",
       "        -1.46590725e-01, -1.10881649e-01,  2.36920044e-02,\n",
       "         1.21671170e-01, -7.66654089e-02,  7.34421834e-02,\n",
       "         1.41709656e-01,  1.23516068e-01,  1.13567263e-01,\n",
       "        -8.18154737e-02, -1.74004316e-01,  2.45118402e-02,\n",
       "         3.13077271e-02, -3.15303057e-02,  1.48888797e-01,\n",
       "         1.34039581e-01, -1.21016540e-02, -6.64855540e-02,\n",
       "         7.64786750e-02, -1.67473592e-02, -1.08083203e-01,\n",
       "         1.20882787e-01,  9.18784738e-02,  2.71982923e-02,\n",
       "         1.11382410e-01,  7.30119795e-02,  4.58904728e-02,\n",
       "         3.60345803e-02,  1.23767473e-01, -2.21287936e-01,\n",
       "         3.91302742e-02,  3.86114568e-02, -1.78869113e-01,\n",
       "        -1.22357100e-01, -6.81218207e-02,  5.62609360e-03,\n",
       "        -9.96578783e-02, -2.20400482e-01, -1.33629106e-02,\n",
       "        -9.32450294e-02, -1.67469233e-02, -1.42413348e-01,\n",
       "         6.53832406e-02,  4.88333404e-02, -5.58822751e-02,\n",
       "         8.35592002e-02, -8.82893801e-02, -3.07362936e-02,\n",
       "        -9.16888714e-02, -4.41937782e-02, -6.41800612e-02,\n",
       "        -7.08619952e-02,  7.05643818e-02,  5.20050228e-02,\n",
       "         3.62830535e-02, -7.85873830e-02, -6.47854507e-02,\n",
       "        -1.73640490e-01,  6.73119128e-02,  1.01507679e-02,\n",
       "         3.22516203e-01,  9.81234908e-02, -8.06093216e-02,\n",
       "        -2.24365778e-02,  2.94020250e-02, -1.50232673e-01,\n",
       "        -4.01954539e-02, -9.23647210e-02, -6.27714545e-02,\n",
       "        -5.29554635e-02, -3.60520668e-02, -1.55516639e-02,\n",
       "         4.61937934e-02,  6.06075339e-02,  1.10431440e-01,\n",
       "         1.58364281e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(cards_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def train_step(self, data):\n",
    "        hole_cards, bets, iterations, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self([[hole_cards],bets])\n",
    "            \n",
    "            loss = tf.reduce_mean(iterations+1 * tf.reduce_sum((targets - predictions)**2, axis = -1), axis=None)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        \n",
    "        gradients = [tf.clip_by_norm(g, 1.0)\n",
    "             for g in gradients]\n",
    "\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.trainable_variables)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DeepCFR_model(output_dim, n_cards, n_bets, n_actions):\n",
    "    \"\"\"\n",
    "    output_dim: dimensionality of embedding\n",
    "    n_cards: a list of card numbers for each phase of the game (e.g. 2 preflop, 3 flop)\n",
    "    n_bets: maximal number of bets in a game\n",
    "    n_actions: number of possible action categories\n",
    "    \"\"\"\n",
    "    \n",
    "    # define inputs\n",
    "    \n",
    "    #info_state = ... (stored_vector)\n",
    "    \n",
    "    #hole_cards = [info_state[:2]]\n",
    "    # ...\n",
    "    \n",
    "    \n",
    "    cards = [tf.keras.Input([n,], name = f\"cards{i}\") for i,n in enumerate(n_cards)]\n",
    "    \n",
    "    \n",
    "    bets = tf.keras.Input([n_bets], name = \"bets\")\n",
    "    \n",
    "    #shape = [n for n in n_cards]\n",
    "    #inp = tf.keras.Input((2,None,None,None),ragged=True)   #\n",
    "    \n",
    "    #cards = inp[0]\n",
    "    #bets = inp[1]\n",
    "    \n",
    "    ### define layers\n",
    "\n",
    "    # embedding layer for each card type (pre-flop, flop, turn, river)\n",
    "    output_dims = [output_dim for _ in range(len(n_cards))]\n",
    "    \n",
    "    embedding_layers = [get_embedding_model(output_dim, num_cards) for num_cards, \n",
    "                        num_output_dims in zip(n_cards, output_dims)]\n",
    "\n",
    "    card1 = tf.keras.layers.Dense(output_dim, activation = \"relu\")\n",
    "    card2 = tf.keras.layers.Dense(output_dim, activation = \"relu\")\n",
    "    card3 = tf.keras.layers.Dense(output_dim, activation = \"relu\")\n",
    "\n",
    "    bet1 = tf.keras.layers.Dense(output_dim)\n",
    "    bet2 = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    comb1 = tf.keras.layers.Dense(output_dim)\n",
    "    comb2 = tf.keras.layers.Dense(output_dim)\n",
    "    comb3 = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    action_head = tf.keras.layers.Dense(n_actions)\n",
    "\n",
    "\n",
    "    # card branch\n",
    "    card_embs = []\n",
    "    for embedding, card_group in zip(embedding_layers, cards):\n",
    "        card_embs.append(embedding(card_group))\n",
    "\n",
    "    card_embs = tf.concat(card_embs, axis= 1)\n",
    "\n",
    "    x = card1(card_embs)\n",
    "    x = card2(x)\n",
    "    x = card3(x)\n",
    "\n",
    "    # bet branch\n",
    "    bet_size = tf.clip_by_value(bets, tf.constant(0.), tf.constant(1e6)) # clip bet sizes\n",
    "    bets_occured = tf.cast(bets >= tf.constant(0.), tf.float32) # check if bet occured\n",
    "    bet_features = tf.concat([bet_size, bets_occured], axis = -1)   # bet size and boolean bet\n",
    "    y = bet1(bet_features)\n",
    "    y = bet2(y)\n",
    "    \n",
    "    # combine bet history and card embedding branches\n",
    "    z = tf.concat([x,y],axis=-1)\n",
    "    z = tf.nn.relu(comb1(z))\n",
    "    z = tf.nn.relu(comb2(z) + z)\n",
    "    z = tf.nn.relu(comb3(z) + z)\n",
    "\n",
    "    # normalize (needed because of bet sizes)\n",
    "    z = (z - tf.math.reduce_mean(z, axis=None)) / tf.math.reduce_std(z, axis=None)\n",
    "\n",
    "    output = action_head(z)\n",
    "\n",
    "    \n",
    "    DeepCFR_model = CustomModel(inputs = [cards, bets], outputs = output)\n",
    "    \n",
    "    return DeepCFR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepCFR_model = get_DeepCFR_model(output_dim = 512, n_cards = [2,3], n_bets = 4, n_actions = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4183457, -1.4132977, -0.2892659]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test Deep CFR Model with batch size of 4\n",
    "\n",
    "\n",
    "\n",
    "hole_cards = tf.constant( [   \n",
    "    [1, 10],                            \n",
    "    #[[7],[19]],                          \n",
    "    #[[35],[51]],                         \n",
    "    #[[23],[12]]                           \n",
    "],dtype=tf.float32)\n",
    "\n",
    "\n",
    "flop = tf.constant([\n",
    "    [2, 9, 8],            \n",
    "    #[[2],[9],[8]],         \n",
    "    #[[2],[9],[8]],           \n",
    "    #[[2],[9],[8]]\n",
    "], dtype = tf.float32)\n",
    "\n",
    "cards_inp = [hole_cards, flop]\n",
    "\n",
    "bets = tf.constant([\n",
    "    [1,2,2,4],                  \n",
    "    #[1,0,2,4],                \n",
    "    #[1,0,2,4],                \n",
    "    #[1,0,2,4]\n",
    "], dtype= tf.float32)\n",
    "\n",
    "\n",
    "DeepCFR_model([cards_inp, bets]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save random training examples with a Memory Object to a hdf5 file\n",
    "\n",
    "\n",
    "\n",
    "### What to do:\n",
    "\n",
    "* Each memory (advantage_memory_player0, advantage_memory_player1 and strategy_memory) should have its own MemoryWriter object with a different file_name set. This is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_random_sample():\n",
    "    \"\"\"\n",
    "    Generates data in a form the network can process\n",
    "    \"\"\"\n",
    "    \n",
    "    hole_cards = np.random.randint(0,51,(1,2,1))\n",
    "\n",
    "    flop_cards = np.random.randint(0,51,(1,3,1))\n",
    "\n",
    "    bet_history = np.random.randint(0,3,(1,12))\n",
    "\n",
    "\n",
    "    info_state = [[hole_cards, flop_cards], bet_history] # this is the form in which the model takes its input\n",
    "\n",
    "    CFR_iteration = np.random.randint(1,40000000)\n",
    "\n",
    "    action_advantages = np.random.random((1,3)) + np.random.randint(-3,3,(1,3)) # target for the network's output\n",
    "    \n",
    "    return info_state, CFR_iteration, action_advantages # input arguments to save_to_memory\n",
    "\n",
    "info_state, iteration, values = generate_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_data_for_memory(info_state, iteration, values):\n",
    "    \"\"\"\n",
    "    Flattens data to store into a memory object.\n",
    "    \"\"\"\n",
    "    flattened_data = np.concatenate(\n",
    "                    [\n",
    "                        info_state[0][0].flatten(),\n",
    "                        info_state[1].flatten(),\n",
    "                        np.array([iteration]),\n",
    "                        values.flatten() \n",
    "                    ],  axis = 0)\n",
    "    \n",
    "    return flattened_data\n",
    "\n",
    "\n",
    "class MemoryWriter(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Keeps track of how many items are already processed for this memory. \n",
    "    It's main purpose is to store the generated data with the save_to_memory method\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, max_size, vector_length, flatten_func, file_name):\n",
    "        \n",
    "        self.max_size = max_size\n",
    "        \n",
    "        self.vector_len = vector_length # flatten the input that we want to store and take len\n",
    "        \n",
    "        self.flatten_func = flatten_func\n",
    "            \n",
    "        self.counter = np.array([0,0]) # can't assign a single number to a dataset in hdf5 files\n",
    "        \n",
    "        self.file_name = file_name\n",
    "        \n",
    "        # load previous counter or initiate memory file\n",
    "        try:\n",
    "            with h5py.File(self.file_name, \"r\") as hf:\n",
    "                self.counter = np.array(hf.get(\"counter\"))\n",
    "            print(\"previous counter loaded\")\n",
    "                \n",
    "        except:\n",
    "            # create new dataset file with a counter and an array\n",
    "            with h5py.File(self.file_name, \"w\") as hf:\n",
    "                \n",
    "                hf.create_dataset(\"counter\", data= self.counter)\n",
    "                hf.create_dataset(\"data\", (self.max_size, self.vector_len), dtype = np.float32)\n",
    "            print(f\"new counter set and dataset of size {(self.max_size, self.vector_len)} is initiated.\")\n",
    "        \n",
    "    def save_to_memory(self, data):\n",
    "        \"\"\"\n",
    "        Takes a list of tuples (info_state, iteration, values) and stores each to the memory hdf5 file.\n",
    "        \n",
    "        Uses Reservoir sampling for samples that exceed the specified max_size.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.file_name, 'r+') as hf:\n",
    "            \n",
    "            # store each tuple in data\n",
    "            for info_state, iteration, values in data:\n",
    "                \n",
    "                self.counter[1] += 1\n",
    "                \n",
    "                # save counter only every 100 steps\n",
    "                if not self.counter[1]%100:\n",
    "                    hf.get(\"counter\")[1] = self.counter[1]\n",
    "                \n",
    "                # if reservoir is not yet full, simply add new sample\n",
    "                if self.counter[1] < self.max_size:\n",
    "\n",
    "                    flattened_data = self.flatten_func(info_state, iteration, values)\n",
    "\n",
    "                    hf.get(\"data\")[self.counter[1]] = flattened_data # fill empty row with data\n",
    "\n",
    "                # if reservoir is full already, randomly replace or not replace old data\n",
    "                else:\n",
    "                    idx = random.randint(0, self.counter[1]) # index to replace (or not)\n",
    "                    if idx < self.max_size:\n",
    "\n",
    "                        flattened_data = self.flatten_func(info_state, iteration, values)\n",
    "\n",
    "                        hf.get(\"data\")[idx] =  flattened_data # replace the old data at idx with the new sample\n",
    "\n",
    "                    else:\n",
    "                        pass # data is not stored in favor of old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new counter set and dataset of size (1000, 18) is initiated.\n"
     ]
    }
   ],
   "source": [
    "m = MemoryWriter(max_size = 1000, vector_length = 18, flatten_func = flatten_data_for_memory,\n",
    "                 file_name = \"value_memory_p1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [generate_random_sample() for _ in range(10000)]\n",
    "\n",
    "m.save_to_memory(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16900\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"advantage_memory.h5\",\"r+\") as hf:\n",
    "    print(np.array(hf.get(\"counter\"))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Code to Train the Model on data in advantage_memory.h5 and strategy_memory.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"advantage_memory.h5\",\"r\") as hf:\n",
    "    print(np.array(hf.get(\"counter\"))[1])\n",
    "    \n",
    "    stored_vector = np.array(hf.get(\"data\")[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_dataset(file_name, batch_size, num_infostates, game_type, num_bets, num_actions):\n",
    "    \"\"\"\n",
    "    Creates a tensorflow dataset from a .h5 file\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def get_input_targets(stored_vector, game_type):\n",
    "        \n",
    "        \n",
    "        \n",
    "        if game_type == \"hole_cards only\":\n",
    "            #indices = [2,8,9]\n",
    "            indices = [2, 2+num_bets, 2+num_bets+1]\n",
    "            hole_cards = stored_vector[:indices[0]]\n",
    "            bets = stored_vector[indices[0]:indices[1]]\n",
    "            iteration = stored_vector[indices[1]]\n",
    "            values = stored_vector[indices[-1]:]\n",
    "            \n",
    "            return tf.constant(hole_cards), tf.constant(bets), tf.constant(iteration), tf.constant(values)\n",
    "        \n",
    "        elif game_type == \"hole_cards + flop\":\n",
    "            indices = [2, 6, 6+num_bets, 6+num_bets+1]\n",
    "            \n",
    "            hole_cards = stored_vector[:indices[0]]\n",
    "            flop_cards = stored_vector[indices[0]:indices[1]]\n",
    "            bets = stored_vector[indices[1]:indices[2]]\n",
    "            iteration = stored_vector[indices[2]]\n",
    "            values = stored_vector[indices[-1]:]\n",
    "            \n",
    "            return tf.constant(hole_cards), tf.constant(flop_cards), tf.constant(bets), tf.constant(iteration), tf.constant(values)\n",
    "\n",
    "\n",
    "        #return network_input, targets, iteration    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def memory_generator():\n",
    "        with h5py.File(file_name,\"r\") as hf:\n",
    "\n",
    "            while True:\n",
    "                #np.array(hf.get(\"counter\"))[1])\n",
    "                idx = random.randint(1,num_infostates)\n",
    "                stored_vector = np.array(hf.get(\"data\")[idx])\n",
    "\n",
    "                yield get_input_targets(stored_vector, game_type)\n",
    "\n",
    "    \n",
    "    if game_type == \"hole_cards only\":\n",
    "        out_signature = (tf.TensorSpec(shape=(2,), dtype=tf.float32),\n",
    "                                       tf.TensorSpec(shape=(num_bets,), dtype=tf.float32),\n",
    "                                       tf.TensorSpec(shape=(), dtype=tf.float32),\n",
    "                                       tf.TensorSpec(shape=(num_actions,), dtype=tf.float32))\n",
    "        \n",
    "    elif game_type == \"hole_cards + flop\":\n",
    "        out_signature = (tf.TensorSpec(shape=(2,), dtype=tf.float32),\n",
    "                         tf.TensorSpec(shape=(3,), dtype=tf.float32),\n",
    "                                       tf.TensorSpec(shape=(num_bets,), dtype=tf.float32),\n",
    "                                       tf.TensorSpec(shape=(), dtype=tf.float32),\n",
    "                                       tf.TensorSpec(shape=(num_actions,), dtype=tf.float32))\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_generator(memory_generator, \n",
    "                                   output_signature= out_signature\n",
    "    ).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_tf_dataset(\"advantage_memory.h5\", 32, 40_000, \"hole_cards only\", 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCFR_Model(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DeepCFR_Model,self).__init__()\n",
    "        self.CFR_model = get_DeepCFR_model(output_dim = 256, n_cards = [2], n_bets = 6, n_actions = 5)\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.CFR_model(inputs)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        \n",
    "        gradients = tape.gradient(loss, self.CFR_model.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.CFR_model.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        \n",
    "        hole_cards, bets, iterations, targets = data\n",
    "        \n",
    "        predictions = self.CFR_model([[hole_cards],bets])\n",
    "        \n",
    "        return tf.reduce_mean(iterations+1 * tf.reduce_sum((targets - predictions)**2, axis = -1), axis=None)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_DeepCFR_model(output_dim = 256, n_cards = [2], n_bets = 6, n_actions = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = \"adam\"\n",
    "loss = None\n",
    "model.compile(optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 194164/Unknown - 3305s 17ms/step - loss: 34.0950"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7a875f4d503b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"advantage_memory.h5\",\"r\") as hf:\n",
    "    array = np.array(hf.get(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.       , 33.       ,  2.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       ,  0.       ,  0.8958747,\n",
       "        0.8958747, -2.433532 , -1.1041254, -2.344612 ], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[40006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(DeepCFR_model, \"plotmodel.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
