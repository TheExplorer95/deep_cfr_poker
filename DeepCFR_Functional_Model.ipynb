{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_model(output_dim, num_cards):\n",
    "    \n",
    "    input_dim_rank = 13\n",
    "    input_dim_suit = 4\n",
    "    input_dim_card = 52\n",
    "\n",
    "    cards_input = tf.keras.Input((num_cards,))\n",
    "\n",
    "    #### EMBEDDING MODEL (used for each group of cards)\n",
    "    \n",
    "    rank_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim_rank, output_dim, embeddings_initializer='uniform',\n",
    "        embeddings_regularizer=None, activity_regularizer=None,\n",
    "        embeddings_constraint=None, mask_zero=False, input_length=None,\n",
    "    )\n",
    "\n",
    "    suit_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim_suit, output_dim, embeddings_initializer='uniform',\n",
    "        embeddings_regularizer=None, activity_regularizer=None,\n",
    "        embeddings_constraint=None, mask_zero=False, input_length=None,\n",
    "    )\n",
    "\n",
    "    card_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim_card, output_dim, embeddings_initializer='uniform',\n",
    "        embeddings_regularizer=None, activity_regularizer=None,\n",
    "        embeddings_constraint=None, mask_zero=False, input_length=None,\n",
    "    )\n",
    "\n",
    "    # cards is a list of card indices (2 for preflop, 3 for flop, 1 for turn, 1 for river)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(cards_input)\n",
    "\n",
    "    valid = tf.cast(x >= tf.constant(0.), tf.float32)\n",
    "\n",
    "    x = tf.clip_by_value(x, clip_value_min = 0, clip_value_max = 1e6)\n",
    "    \n",
    "    embs = card_embedding(x) + rank_embedding(x // 4) + suit_embedding(x%4)\n",
    "    \n",
    "    embs = embs * tf.expand_dims(valid, axis=-1)\n",
    "        \n",
    "    embs = tf.reduce_sum(embs , axis=1) # sum over num_cards card embeddings\n",
    "    \n",
    "    model = tf.keras.Model(cards_input, embs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "#card1 = tf.keras.layers.Dense(output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_embedding_model(256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_input = tf.constant([[[1],[10],[3]], \n",
    "                           [[1],[10],[3]], \n",
    "                           [[1],[10],[3]], \n",
    "                           [[1],[10],[3]]],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 256), dtype=float32, numpy=\n",
       "array([[ 0.14479068, -0.13707975,  0.17693862, ..., -0.11987062,\n",
       "         0.05106021,  0.0828777 ],\n",
       "       [ 0.14479068, -0.13707975,  0.17693862, ..., -0.11987062,\n",
       "         0.05106021,  0.0828777 ],\n",
       "       [ 0.14479068, -0.13707975,  0.17693862, ..., -0.11987062,\n",
       "         0.05106021,  0.0828777 ],\n",
       "       [ 0.14479068, -0.13707975,  0.17693862, ..., -0.11987062,\n",
       "         0.05106021,  0.0828777 ]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(cards_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DeepCFR_model(output_dim, n_cards, n_bets, n_actions):\n",
    "    \"\"\"\n",
    "    output_dim: dimensionality of embedding\n",
    "    n_cards: a list of card numbers for each phase of the game (e.g. 2 preflop, 3 flop)\n",
    "    n_bets: maximal number of bets in a game\n",
    "    n_actions: number of possible action categories\n",
    "    \"\"\"\n",
    "    \n",
    "    # define inputs\n",
    "    cards = [tf.keras.Input([n,]) for n in n_cards]\n",
    "    bets = tf.keras.Input([n_bets,])\n",
    "\n",
    "    ### define layers\n",
    "\n",
    "    # embedding layer for each card type (pre-flop, flop, turn, river)\n",
    "    output_dims = [output_dim for _ in range(len(n_cards))]\n",
    "    \n",
    "    embedding_layers = [get_embedding_model(output_dim, num_cards) for num_cards, \n",
    "                        num_output_dims in zip(n_cards, output_dims)]\n",
    "\n",
    "    card1 = tf.keras.layers.Dense(output_dim, activation = \"relu\")\n",
    "    card2 = tf.keras.layers.Dense(output_dim, activation = \"relu\")\n",
    "    card3 = tf.keras.layers.Dense(output_dim, activation = \"relu\")\n",
    "\n",
    "    bet1 = tf.keras.layers.Dense(output_dim)\n",
    "    bet2 = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    comb1 = tf.keras.layers.Dense(output_dim)\n",
    "    comb2 = tf.keras.layers.Dense(output_dim)\n",
    "    comb3 = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    action_head = tf.keras.layers.Dense(n_actions)\n",
    "\n",
    "\n",
    "    # card branch\n",
    "    card_embs = []\n",
    "    for embedding, card_group in zip(embedding_layers, cards):\n",
    "        card_embs.append(embedding(card_group))\n",
    "\n",
    "    card_embs = tf.concat(card_embs, axis= 1)\n",
    "\n",
    "    x = card1(card_embs)\n",
    "    x = card2(x)\n",
    "    x = card3(x)\n",
    "\n",
    "    # bet branch\n",
    "    bet_size = tf.clip_by_value(bets, tf.constant(0.), tf.constant(1e6)) # clip bet sizes\n",
    "    bets_occured = tf.cast(bets >= tf.constant(0.), tf.float32) # check if bet occured\n",
    "    bet_features = tf.concat([bet_size, bets_occured], axis = -1)   # bet size and boolean bet\n",
    "    y = bet1(bet_features)\n",
    "    y = bet2(y)\n",
    "    \n",
    "    # combine bet history and card embedding branches\n",
    "    z = tf.concat([x,y],axis=-1)\n",
    "    z = comb1(z)\n",
    "    z = tf.nn.relu(comb2(z) + z)\n",
    "    z = tf.nn.relu(comb3(z) + z)\n",
    "\n",
    "    # normalize (needed because of bet sizes)\n",
    "    z = (z - tf.math.reduce_mean(z, axis=None)) / tf.math.reduce_std(z, axis=None)\n",
    "\n",
    "    output = action_head(z)\n",
    "\n",
    "\n",
    "    DeepCFR_model = tf.keras.Model(inputs = [cards, bets], outputs = output)\n",
    "    \n",
    "    return DeepCFR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepCFR_model = get_DeepCFR_model(output_dim = 256, n_cards = [2,3], n_bets = 4, n_actions = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5071793 ,  0.24127457, -0.6368238 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test Deep CFR Model with batch size of 4\n",
    "\n",
    "\n",
    "\n",
    "hole_cards = tf.constant( [   \n",
    "    [[1],[10]],                            \n",
    "    #[[7],[19]],                          \n",
    "    #[[35],[51]],                         \n",
    "    #[[23],[12]]                           \n",
    "],dtype=tf.float32)\n",
    "\n",
    "\n",
    "flop = tf.constant([\n",
    "    [[2],[9],[8]],            \n",
    "    #[[2],[9],[8]],         \n",
    "    #[[2],[9],[8]],           \n",
    "    #[[2],[9],[8]]\n",
    "], dtype = tf.float32)\n",
    "\n",
    "cards_inp = [hole_cards, flop]\n",
    "\n",
    "bets = tf.constant([\n",
    "    [1,2,2,4],                  \n",
    "    #[1,0,2,4],                \n",
    "    #[1,0,2,4],                \n",
    "    #[1,0,2,4]\n",
    "], dtype= tf.float32)\n",
    "\n",
    "\n",
    "DeepCFR_model([cards_inp, bets]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save random training examples with a Memory Object to a hdf5 file\n",
    "\n",
    "\n",
    "\n",
    "### What to do:\n",
    "\n",
    "* Each memory (advantage_memory_player0, advantage_memory_player1 and strategy_memory) should have its own MemoryWriter object with a different file_name set. This is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_random_sample():\n",
    "    \"\"\"\n",
    "    Generates data in a form the network can process\n",
    "    \"\"\"\n",
    "    \n",
    "    hole_cards = np.random.randint(0,51,(1,2,1))\n",
    "\n",
    "    flop_cards = np.random.randint(0,51,(1,3,1))\n",
    "\n",
    "    bet_history = np.random.randint(0,3,(1,12))\n",
    "\n",
    "\n",
    "    info_state = [[hole_cards, flop_cards], bet_history] # this is the form in which the model takes its input\n",
    "\n",
    "    CFR_iteration = np.random.randint(1,40000000)\n",
    "\n",
    "    action_advantages = np.random.random((1,3)) + np.random.randint(-3,3,(1,3)) # target for the network's output\n",
    "    \n",
    "    return info_state, CFR_iteration, action_advantages # input arguments to save_to_memory\n",
    "\n",
    "info_state, iteration, values = generate_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_data_for_memory(info_state, iteration, values):\n",
    "    \"\"\"\n",
    "    Flattens data to store into a memory object.\n",
    "    \"\"\"\n",
    "    flattened_data = np.concatenate(\n",
    "                    [\n",
    "                        info_state[0][0].flatten(),\n",
    "                        info_state[1].flatten(),\n",
    "                        np.array([iteration]),\n",
    "                        values.flatten() \n",
    "                    ],  axis = 0)\n",
    "    \n",
    "    return flattened_data\n",
    "\n",
    "\n",
    "class MemoryWriter(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Keeps track of how many items are already processed for this memory. \n",
    "    It's main purpose is to store the generated data with the save_to_memory method\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, max_size, vector_length, flatten_func, file_name):\n",
    "        \n",
    "        self.max_size = max_size\n",
    "        \n",
    "        self.vector_len = vector_length # flatten the input that we want to store and take len\n",
    "        \n",
    "        self.flatten_func = flatten_func\n",
    "            \n",
    "        self.counter = np.array([0,0]) # can't assign a single number to a dataset in hdf5 files\n",
    "        \n",
    "        self.file_name = file_name\n",
    "        \n",
    "        # load previous counter or initiate memory file\n",
    "        try:\n",
    "            with h5py.File(self.file_name, \"r\") as hf:\n",
    "                self.counter = np.array(hf.get(\"counter\"))\n",
    "            print(\"previous counter loaded\")\n",
    "                \n",
    "        except:\n",
    "            # create new dataset file with a counter and an array\n",
    "            with h5py.File(self.file_name, \"w\") as hf:\n",
    "                \n",
    "                hf.create_dataset(\"counter\", data= self.counter)\n",
    "                hf.create_dataset(\"data\", (self.max_size, self.vector_len), dtype = np.float32)\n",
    "            print(f\"new counter set and dataset of size {(self.max_size, self.vector_len)} is initiated.\")\n",
    "        \n",
    "    def save_to_memory(self, data):\n",
    "        \"\"\"\n",
    "        Takes a list of tuples (info_state, iteration, values) and stores each to the memory hdf5 file.\n",
    "        \n",
    "        Uses Reservoir sampling for samples that exceed the specified max_size.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.file_name, 'r+') as hf:\n",
    "            \n",
    "            # store each tuple in data\n",
    "            for info_state, iteration, values in data:\n",
    "                \n",
    "                self.counter[1] += 1\n",
    "                \n",
    "                # save counter only every 100 steps\n",
    "                if not self.counter[1]%100:\n",
    "                    hf.get(\"counter\")[1] = self.counter[1]\n",
    "                \n",
    "                # if reservoir is not yet full, simply add new sample\n",
    "                if self.counter[1] < self.max_size:\n",
    "\n",
    "                    flattened_data = self.flatten_func(info_state, iteration, values)\n",
    "\n",
    "                    hf.get(\"data\")[self.counter[1]] = flattened_data # fill empty row with data\n",
    "\n",
    "                # if reservoir is full already, randomly replace or not replace old data\n",
    "                else:\n",
    "                    idx = random.randint(0, self.counter[1]) # index to replace (or not)\n",
    "                    if idx < self.max_size:\n",
    "\n",
    "                        flattened_data = self.flatten_func(info_state, iteration, values)\n",
    "\n",
    "                        hf.get(\"data\")[idx] =  flattened_data # replace the old data at idx with the new sample\n",
    "\n",
    "                    else:\n",
    "                        pass # data is not stored in favor of old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous counter loaded\n"
     ]
    }
   ],
   "source": [
    "m = MemoryWriter(max_size = 1000, vector_length = 18, flatten_func = flatten_data_for_memory,\n",
    "                 file_name = \"value_memory_p1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [generate_random_sample() for _ in range(10000)]\n",
    "\n",
    "m.save_to_memory(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(DeepCFR_model, \"plotmodel.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
